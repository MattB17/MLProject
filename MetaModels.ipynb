{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Models\n",
    "\n",
    "In this notebook we prototype a set of Meta Models. In particular, we use the s-values trained using the chainRec algorithm and use these as input features to our model. These are combined with book level features in the hopes to enhance the predictive accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import scipy.sparse as sp\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading S-Values\n",
    "\n",
    "We load the S-Values from the ChainRec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_DIR = './mappings/'\n",
    "\n",
    "s_values_df = pd.read_csv(MAPPING_DIR+\"goodreads_s_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['user_number', 'item_number', 's1', 's2', 's3', 's4']\n",
    "\n",
    "s_values_df = s_values_df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values_df['user_number'] = s_values_df['user_number'].apply(lambda x: str(x))\n",
    "s_values_df['item_number'] = s_values_df['item_number'].apply(lambda x: str(x))\n",
    "s_values_df['user_item_id'] = s_values_df['user_number'] + \"-\" + s_values_df['item_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DATA_DIR = \"./output_data/\"\n",
    "\n",
    "train_df_processed = pd.read_csv(OUTPUT_DATA_DIR+\"text_processed_training.csv\")\n",
    "val_df_processed = pd.read_csv(OUTPUT_DATA_DIR+\"text_processed_validation.csv\")\n",
    "test_df_processed = pd.read_csv(OUTPUT_DATA_DIR+\"text_processed_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mapping(mapping_file):\n",
    "    \"\"\"Loads the mapping from `mapping_file`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mapping_file: str\n",
    "        The name of the mapping file to import.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame created from the mapping.\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(\"mappings\", \"{}.csv\".format(mapping_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_map = load_mapping(\"user_map\")\n",
    "book_map = load_mapping(\"book_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_map['book_id'] = book_map['book_id'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_id(data_df, u_map, i_map):\n",
    "    data_df['book_id'] = data_df['book_id'].apply(lambda x: str(x))\n",
    "    data_df = pd.merge(data_df, u_map, how=\"left\", on=[\"user_id\"])\n",
    "    data_df = pd.merge(data_df, i_map, how=\"left\", on=[\"book_id\"])\n",
    "    data_df['user_number'] = data_df['user_number'].apply(lambda x: str(x))\n",
    "    data_df['book_number'] = data_df['book_number'].apply(lambda x: str(x))\n",
    "    data_df['user_item_id'] = data_df['user_number'] + \"-\" + data_df['book_number']\n",
    "    return data_df.drop(columns=['user_number', 'book_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_user_item_id(train_df_processed, user_map, book_map)\n",
    "val_df = create_user_item_id(val_df_processed, user_map, book_map)\n",
    "test_df = create_user_item_id(test_df_processed, user_map, book_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values_df.drop(columns=['user_number', 'item_number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_s = pd.merge(train_df, s_values_df, how='left', on=['user_item_id'])\n",
    "val_df_s = pd.merge(val_df, s_values_df, how='left', on=['user_item_id'])\n",
    "test_df_s = pd.merge(test_df, s_values_df, how='left', on=['user_item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_s.drop(columns=['user_item_id'], inplace=True)\n",
    "val_df_s.drop(columns=['user_item_id'], inplace=True)\n",
    "test_df_s.drop(columns=['user_item_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_s.to_csv(OUTPUT_DATA_DIR+\"training_s_vals.csv\", index=False)\n",
    "val_df_s.to_csv(OUTPUT_DATA_DIR+\"validation_s_vals.csv\", index=False)\n",
    "test_df_s.to_csv(OUTPUT_DATA_DIR+\"testing_s_vals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['text_reviews_count', 'is_ebook', 'average_rating', 'num_pages',\n",
    "                   'ratings_count', 'is_translated', 'is_in_series', 'series_length', \n",
    "                   'is_paperback', 'is_hardcover', 'is_audio', 'is_other_format', 'from_penguin', \n",
    "                   'from_harpercollins', 'from_university_press', 'from_vintage',\n",
    "                   'from_createspace', 'other_publisher', 'author_a', 'author_b', 'author_c',\n",
    "                   'author_d', 'author_e', 'author_f', 'author_other', 's1', 's2', 's3', 's4']\n",
    "X_train_reg = train_df_s[columns_to_keep]\n",
    "X_val_reg = val_df_s[columns_to_keep]\n",
    "X_test_reg = test_df_s[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform_columns(data_df, cols):\n",
    "    \"\"\"Applies a log transform to `cols` in `data_df`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_df: pd.DataFrame\n",
    "        The DataFrame in which the columns will be transformed.\n",
    "    cols: collection\n",
    "        The columns in `data_df` to be log scaled.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame obtained from `data_df` after log scaling\n",
    "        the columns `cols`.\n",
    "\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        data_df[col] = data_df[col].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-49ee2668773d>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[col] = data_df[col].apply(lambda x: np.log(x) if x > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "log_transform_cols = ['text_reviews_count', 'ratings_count']\n",
    "X_train_reg = log_transform_columns(X_train_reg, log_transform_cols)\n",
    "X_val_reg = log_transform_columns(X_val_reg, log_transform_cols)\n",
    "X_test_reg = log_transform_columns(X_test_reg, log_transform_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_reg1 = min_max_scaler.fit_transform(X_train_reg)\n",
    "X_val_reg1 = min_max_scaler.transform(X_val_reg)\n",
    "X_test_reg1 = min_max_scaler.transform(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6770555855780461\n",
      "Validation AUC: 0.5590056441175538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "reg_model = LogisticRegression(max_iter=200)\n",
    "reg_model.fit(X_train_reg1, train_df_s['recommended'])\n",
    "\n",
    "train_AUC = roc_auc_score(train_df_s['recommended'], reg_model.predict(X_train_reg1))\n",
    "val_AUC = roc_auc_score(val_df_s['recommended'], reg_model.predict(X_val_reg1))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6635181386123419\n",
      "Validation AUC: 0.5960578200432686\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(X_train_reg1, train_df_processed['recommended'])\n",
    "train_AUC = roc_auc_score(\n",
    "    train_df_processed['recommended'], xg_cls.predict(X_train_reg1))\n",
    "val_AUC = roc_auc_score(\n",
    "    val_df_processed['recommended'], xg_cls.predict(X_val_reg1))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(val):\n",
    "    \"\"\"Applies the sigmoid function to `val`.\n",
    "    \n",
    "    The sigmoid function has the form\n",
    "    f(x) = 1 / (1 + exp(-x))\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    val: float\n",
    "        The operand to the sigmoid function.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The result of applying the sigmoid\n",
    "        function to `val`.\n",
    "    \n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_s_values(data_df):\n",
    "    \"\"\"Applies the sigmoid function to the s values in `data_df`.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    data_df: pd.DataFrame\n",
    "        The DataFrame for which the operation is performed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame that results from scaling the s values\n",
    "        in `data_df`.\n",
    "    \n",
    "    \"\"\"\n",
    "    for s_col in [\"s1\", \"s2\", \"s3\", \"s4\"]:\n",
    "        data_df[s_col] = data_df[s_col].apply(lambda x: sigmoid(x))\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-4768feb00e52>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[s_col] = data_df[s_col].apply(lambda x: sigmoid(x))\n"
     ]
    }
   ],
   "source": [
    "X_train_reg2 = scale_s_values(X_train_reg)\n",
    "X_val_reg2 = scale_s_values(X_val_reg)\n",
    "X_test_reg2 = scale_s_values(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6598480261682507\n",
      "Validation AUC: 0.5752980498317812\n"
     ]
    }
   ],
   "source": [
    "reg_model = LogisticRegression(max_iter=200)\n",
    "reg_model.fit(X_train_reg2, train_df_s['recommended'])\n",
    "\n",
    "train_AUC = roc_auc_score(train_df_s['recommended'], reg_model.predict(X_train_reg2))\n",
    "val_AUC = roc_auc_score(val_df_s['recommended'], reg_model.predict(X_val_reg2))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6635181386123419\n",
      "Validation AUC: 0.5960578200432686\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(X_train_reg2, train_df_processed['recommended'])\n",
    "train_AUC = roc_auc_score(\n",
    "    train_df_processed['recommended'], xg_cls.predict(X_train_reg2))\n",
    "val_AUC = roc_auc_score(\n",
    "    val_df_processed['recommended'], xg_cls.predict(X_val_reg2))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = train_df_s[['book_id', 'cleaned_text']]\n",
    "book_df = book_df.drop_duplicates(subset=['book_id'])\n",
    "\n",
    "book_df['cleaned_text'] = book_df['cleaned_text'].apply(lambda x: \"\" if pd.isnull(x) else x)\n",
    "\n",
    "w2v = Word2Vec(list(book_df['cleaned_text']), size=200, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_book_vector(book_text, vec_length):\n",
    "    \"\"\"Creates a vector for the book given by `book_text`.\n",
    "\n",
    "    The word vectors for each word in `book_text` are\n",
    "    averaged to build a vector for the book.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    book_text: str\n",
    "        The book text for which the vector is generated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vector\n",
    "        A vector for the book.\n",
    "\n",
    "    \"\"\"\n",
    "    text_vecs = [word for word in str(book_text) if word in w2v.wv.vocab]\n",
    "    if len(text_vecs) > 0:\n",
    "        return np.mean(w2v[text_vecs], axis=0)\n",
    "    return np.zeros(vec_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-4533799a3578>:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  return np.mean(w2v[text_vecs], axis=0)\n"
     ]
    }
   ],
   "source": [
    "train_df_s['book_vector'] = train_df_s['cleaned_text'].apply(lambda x: create_book_vector(x, 200))\n",
    "val_df_s['book_vector'] = val_df_s['cleaned_text'].apply(lambda x: create_book_vector(x, 200))\n",
    "test_df_s['book_vector'] = test_df_s['cleaned_text'].apply(lambda x: create_book_vector(x, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_book_vec_df(book_vecs, indices):\n",
    "    \"\"\"Creates a dataframe from `book_vecs`.\n",
    "\n",
    "    Each numpy array in `book_vecs` is converted to a\n",
    "    row in the resulting dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    book_vecs: list\n",
    "        A list of numpy arrays where each array corresponds\n",
    "        to the book vector for a book.\n",
    "    indicies: np.array\n",
    "        A numpy array of indices for the DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame obtained from converting `review_vecs`\n",
    "        to a dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    book_vec_df = pd.DataFrame(np.vstack(book_vecs))\n",
    "    book_vec_df.columns = [\"word\" + str(col) for col in book_vec_df.columns]\n",
    "    book_vec_df.index = indices\n",
    "    return book_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wv = create_book_vec_df(train_df_s['book_vector'], train_df_s.index)\n",
    "val_wv = create_book_vec_df(val_df_s['book_vector'], val_df_s.index)\n",
    "test_wv = create_book_vec_df(test_df_s['book_vector'], test_df_s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_reg3 = min_max_scaler.fit_transform(X_train_reg2)\n",
    "X_val_reg3 = min_max_scaler.transform(X_val_reg2)\n",
    "X_test_reg3 = min_max_scaler.transform(X_test_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg_df = pd.DataFrame(np.vstack(X_train_reg3))\n",
    "X_train_reg_df.index = train_df_s.index\n",
    "\n",
    "X_val_reg_df = pd.DataFrame(np.vstack(X_val_reg3))\n",
    "X_val_reg_df.index = val_df_s.index\n",
    "\n",
    "X_test_reg_df = pd.DataFrame(np.vstack(X_test_reg3))\n",
    "X_test_reg_df.index = test_df_s.index\n",
    "\n",
    "X_train_wv_reg = sp.csr_matrix(pd.concat([train_wv, X_train_reg_df], axis=1))\n",
    "X_val_wv_reg = sp.csr_matrix(pd.concat([val_wv, X_val_reg_df], axis=1))\n",
    "X_test_wv_reg = sp.csr_matrix(pd.concat([test_wv, X_test_reg_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6635181386123419\n",
      "Validation AUC: 0.5960578200432686\n"
     ]
    }
   ],
   "source": [
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(X_train_wv_reg, train_df_processed['recommended'])\n",
    "train_AUC = roc_auc_score(\n",
    "    train_df_processed['recommended'], xg_cls.predict(X_train_wv_reg))\n",
    "val_AUC = roc_auc_score(\n",
    "    val_df_processed['recommended'], xg_cls.predict(X_val_wv_reg))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = ['s1', 's2', 's3', 's4', 'recommended']\n",
    "\n",
    "s_train = train_df_s[s_cols]\n",
    "s_val = val_df_s[s_cols]\n",
    "s_test = test_df_s[s_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s = s_train.drop(columns=['recommended'])\n",
    "X_val_s = s_val.drop(columns=['recommended'])\n",
    "X_test_s = s_test.drop(columns=['recommended'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6538201668630219\n",
      "Validation AUC: 0.5327062016726037\n"
     ]
    }
   ],
   "source": [
    "reg_model = LogisticRegression(max_iter=200)\n",
    "reg_model.fit(X_train_s, s_train['recommended'])\n",
    "\n",
    "train_AUC = roc_auc_score(s_train['recommended'], reg_model.predict(X_train_s))\n",
    "val_AUC = roc_auc_score(s_val['recommended'], reg_model.predict(X_val_s))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.645297665355641\n",
      "Validation AUC: 0.579378306728969\n"
     ]
    }
   ],
   "source": [
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(X_train_s, s_train['recommended'])\n",
    "train_AUC = roc_auc_score(\n",
    "    s_train['recommended'], xg_cls.predict(X_train_s))\n",
    "val_AUC = roc_auc_score(\n",
    "    s_val['recommended'], xg_cls.predict(X_val_s))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.652354968917165\n",
      "Validation AUC: 0.5567303402118982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ranfor_model = RandomForestClassifier(n_estimators=500, max_depth=2)\n",
    "ranfor_model.fit(X_train_s, s_train['recommended'])\n",
    "\n",
    "train_AUC = roc_auc_score(\n",
    "    s_train['recommended'], ranfor_model.predict(X_train_s))\n",
    "val_AUC = roc_auc_score(\n",
    "    s_val['recommended'], ranfor_model.predict(X_val_s))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(X_train_s, s_train['recommended'])\n",
    "\n",
    "s_train_preds = xg_cls.predict(X_train_s)\n",
    "s_val_preds = xg_cls.predict(X_val_s)\n",
    "s_test_preds = xg_cls.predict(X_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['text_reviews_count', 'is_ebook', 'average_rating', 'num_pages',\n",
    "                   'ratings_count', 'is_translated', 'is_in_series', 'series_length', \n",
    "                   'is_paperback', 'is_hardcover', 'is_audio', 'is_other_format', 'from_penguin', \n",
    "                   'from_harpercollins', 'from_university_press', 'from_vintage',\n",
    "                   'from_createspace', 'other_publisher', 'author_a', 'author_b', 'author_c',\n",
    "                   'author_d', 'author_e', 'author_f', 'author_other']\n",
    "X_train_reg = train_df_s[columns_to_keep]\n",
    "X_val_reg = val_df_s[columns_to_keep]\n",
    "X_test_reg = test_df_s[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-49ee2668773d>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df[col] = data_df[col].apply(lambda x: np.log(x) if x > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "log_transform_cols = ['text_reviews_count', 'ratings_count']\n",
    "X_train_reg = log_transform_columns(X_train_reg, log_transform_cols)\n",
    "X_val_reg = log_transform_columns(X_val_reg, log_transform_cols)\n",
    "X_test_reg = log_transform_columns(X_test_reg, log_transform_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_reg1 = min_max_scaler.fit_transform(X_train_reg)\n",
    "X_val_reg1 = min_max_scaler.transform(X_val_reg)\n",
    "X_test_reg1 = min_max_scaler.transform(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg_df = pd.DataFrame(np.vstack(X_train_reg1))\n",
    "X_train_reg_df.index = train_df_s.index\n",
    "\n",
    "X_val_reg_df = pd.DataFrame(np.vstack(X_val_reg1))\n",
    "X_val_reg_df.index = val_df_s.index\n",
    "\n",
    "X_test_reg_df = pd.DataFrame(np.vstack(X_test_reg1))\n",
    "X_test_reg_df.index = test_df_s.index\n",
    "\n",
    "X_train_wv_reg = sp.csr_matrix(pd.concat([train_wv, X_train_reg_df], axis=1))\n",
    "X_val_wv_reg = sp.csr_matrix(pd.concat([val_wv, X_val_reg_df], axis=1))\n",
    "X_test_wv_reg = sp.csr_matrix(pd.concat([test_wv, X_test_reg_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6742530422009975\n",
      "Validation AUC: 0.6135375347776293\n"
     ]
    }
   ],
   "source": [
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=2, n_estimators=2000)\n",
    "\n",
    "xg_cls.fit(X_train_wv_reg, train_df_processed['recommended'])\n",
    "\n",
    "xgb_train_preds = xg_cls.predict(X_train_wv_reg)\n",
    "xgb_val_preds = xg_cls.predict(X_val_wv_reg)\n",
    "xgb_test_preds = xg_cls.predict(X_test_wv_reg)\n",
    "\n",
    "train_AUC = roc_auc_score(\n",
    "    train_df_processed['recommended'], xgb_train_preds)\n",
    "val_AUC = roc_auc_score(\n",
    "    val_df_processed['recommended'], xgb_val_preds)\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = pd.DataFrame({'s_preds': s_train_preds,\n",
    "                           'xgb_preds': xgb_train_preds})\n",
    "\n",
    "val_meta = pd.DataFrame({'s_preds': s_val_preds,\n",
    "                           'xgb_preds': xgb_val_preds})\n",
    "\n",
    "test_meta = pd.DataFrame({'s_preds': s_test_preds,\n",
    "                          'xgb_preds': xgb_test_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6742530422009975\n",
      "Validation AUC: 0.6135375347776293\n"
     ]
    }
   ],
   "source": [
    "reg_model = LogisticRegression(max_iter=200)\n",
    "reg_model.fit(train_meta, s_train['recommended'])\n",
    "\n",
    "train_AUC = roc_auc_score(s_train['recommended'], reg_model.predict(train_meta))\n",
    "val_AUC = roc_auc_score(s_val['recommended'], reg_model.predict(val_meta))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC: 0.6742530422009975\n",
      "Validation AUC: 0.6135375347776293\n"
     ]
    }
   ],
   "source": [
    "xg_cls = XGBClassifier(\n",
    "    objective='binary:logistic', learning_rate=0.1,\n",
    "    max_depth=1, n_estimators=10)\n",
    "\n",
    "xg_cls.fit(train_meta, s_train['recommended'])\n",
    "train_AUC = roc_auc_score(\n",
    "    s_train['recommended'], xg_cls.predict(train_meta))\n",
    "val_AUC = roc_auc_score(\n",
    "    s_val['recommended'], xg_cls.predict(val_meta))\n",
    "\n",
    "print(\"Training AUC: {}\".format(train_AUC))\n",
    "print(\"Validation AUC: {}\".format(val_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2515-env-3.8",
   "language": "python",
   "name": "csc2515-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
