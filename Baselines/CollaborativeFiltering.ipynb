{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Baseline Model\n",
    "\n",
    "In this notebook we build a collaborative filtering model to serve as a baseline\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DATA_DIR = \"./output_data/\"\n",
    "\n",
    "train_df = pd.read_csv(OUTPUT_DATA_DIR+\"interactions_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_csv(OUTPUT_DATA_DIR+\"interactions_validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering - Item to Item Similarity Based on Ratings\n",
    "\n",
    "The predicted rating will be the average of the average rating for the most similar books.\n",
    "\n",
    "We will be using kNN and so the predicted rating for a book will be the average rating for the `k` closest books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['book_id'] = train_df['book_id'].astype(\"category\")\n",
    "train_df['user_id'] = train_df['user_id'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "item_matrix = train_df.pivot(index='book_id', columns='user_id', values='rating').fillna(0)\n",
    "item_train_matrix = sp.csr_matrix(item_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit a few KNN models for various values of `k`. Note that there are way more users than books and so we will keep `k` relatively small. We will try `k = [1, 2, 5, 10]` initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "rated_df = train_df[train_df['rated'] == 1]\n",
    "\n",
    "train_item_avg = rated_df.groupby(rated_df['book_id'], as_index=False)['rating'].mean()\n",
    "train_item_avg.columns = ['book_id', 'book_average']\n",
    "train_item_avg = train_item_avg.set_index('book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn_model(train_matrix, k):\n",
    "    \"\"\"Builds a kNN model on `train_matrix` with `k` neighbours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_matrix: sp.csr_matrix\n",
    "        The sparse matrix used to build the kNN model.\n",
    "    k: int\n",
    "        The number of neighbours to use in the kNN model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    NearestNeighbors\n",
    "        A NearestNeighbors model fit to `train_matrix`.\n",
    "    \n",
    "    \"\"\"\n",
    "    model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=k)\n",
    "    model_knn.fit(train_matrix)\n",
    "    return model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_preds_from_knn(knn_model, train_matrix, items, item_avgs):\n",
    "    \"\"\"Gets the kNN predictions for the items in `items`.\n",
    "    \n",
    "    This assumes that every item in items was fit on the\n",
    "    knn_model. This is just a precomputation step to get\n",
    "    the predictions for items in the training set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    knn_model: NearestNeighbors\n",
    "        A NearestNeighbors model that has been fit.\n",
    "    train_matrix: sp.csr_matrix\n",
    "        The sparse matrix representing the training data.\n",
    "    items: np.array\n",
    "        An array of item indices for items in `knn_model`.\n",
    "    item_avgs: pd.DataFrame\n",
    "        A pandas dataframe containing the average rating for\n",
    "        each item in `items`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing the predicted rating for each item\n",
    "        in `items`.\n",
    "    \n",
    "    \"\"\"\n",
    "    item_neighbors = np.asarray(knn_model.kneighbors(train_matrix, return_distance=False))\n",
    "    knn_avgs = np.zeros(len(item_neighbors))   # this is more efficient than appending multiple times (no resizing)\n",
    "    for i in range(len(item_neighbors)):\n",
    "        knn_avgs[i] = item_avgs['book_average'][items[item_neighbors[i]]].mean()    # average of average ratings for neighbors\n",
    "    return pd.concat([pd.DataFrame(items, columns=['book_id']),\n",
    "                      pd.DataFrame(knn_avgs, columns=['book_rating'])],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(X, item_preds, default_val, merge_col):\n",
    "    \"\"\"Predicts the item ratings for the items in `X`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        The DataFrame of features.\n",
    "    item_preds: pd.DataFrame\n",
    "        The DataFrame of predicted ratings for the items.\n",
    "    default_val: float\n",
    "        A default rating used for unseen items.\n",
    "    merge_col: str\n",
    "        The column to merge on.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing the predicted item ratings for\n",
    "        the records in `X`.\n",
    "    \n",
    "    \"\"\"\n",
    "    id_col = \"{}_id\".format(merge_col)\n",
    "    rating_col = \"{}_rating\".format(merge_col)\n",
    "    df_item = pd.merge(X, item_preds, how='left', on=[id_col])\n",
    "    df_item[rating_col] = df_item[rating_col].fillna(default_val)\n",
    "    df_item.index = X.index\n",
    "    return df_item[rating_col].apply(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_knn_train_validation_preds(train_df, val_df, train_matrix, k, items, item_avgs):\n",
    "    \"\"\"Gets predictions on `train_df` and `val_df` from a kNN model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df: pd.DataFrame\n",
    "        A DataFrame of the training data.\n",
    "    val_df: pd.DataFrame\n",
    "        A DataFrame of the validation data.\n",
    "    train_matrix: sp.csr_matrix\n",
    "        The sparse matrix used to train the kNN model.\n",
    "    k: int\n",
    "        The number of neighbours in the kNN model.\n",
    "    items: np.array\n",
    "        An array of strings representing the ids of the\n",
    "        items used in training.\n",
    "    item_avgs: pd.DataFrame\n",
    "        A DataFrame containing the average rating for the\n",
    "        items in `items`.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array, np.array\n",
    "        Arrays of predictions on the training and validation sets, respectively.\n",
    "    \n",
    "    \"\"\"\n",
    "    knn_model = build_knn_model(train_matrix, k)\n",
    "    knn_preds = get_item_preds_from_knn(knn_model, train_matrix, items, item_avgs)\n",
    "    \n",
    "    # prediction for a new book\n",
    "    new_book_vec = np.zeros(train_matrix.shape[1])\n",
    "    new_book_neighbours = knn_model.kneighbors(new_book_vec.reshape(1, -1), return_distance=False)\n",
    "    new_book_pred = item_avgs['book_average'][items[new_book_neighbours[0]]].mean()\n",
    "    \n",
    "    train_pred = predict_ratings(train_df, knn_preds, new_book_pred, \"book\")\n",
    "    val_pred = predict_ratings(val_df, knn_preds, new_book_pred, \"book\")\n",
    "    return train_pred, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with k = 1\n",
      "---------------\n",
      "Training AUC: 0.5067737123901904\n",
      "Validation AUC: 0.5018497724649386\n",
      "\n",
      "kNN with k = 2\n",
      "---------------\n",
      "Training AUC: 0.5032251774455084\n",
      "Validation AUC: 0.5015468723614261\n",
      "\n",
      "kNN with k = 5\n",
      "---------------\n",
      "Training AUC: 0.5000900069813997\n",
      "Validation AUC: 0.49993359484898875\n",
      "\n",
      "kNN with k = 10\n",
      "---------------\n",
      "Training AUC: 0.5\n",
      "Validation AUC: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "k_vals = [1, 2, 5, 10]\n",
    "train_MSEs = [None for _ in range(4)]\n",
    "val_MSEs = [None for _ in range(4)]\n",
    "\n",
    "for i in range(len(k_vals)):\n",
    "    k = k_vals[i]\n",
    "    print(\"kNN with k = {}\".format(k))\n",
    "    print(\"---------------\")\n",
    "    train_preds, val_preds = get_item_knn_train_validation_preds(\n",
    "        train_df, val_df, item_train_matrix, k, item_matrix.index, train_item_avg)\n",
    "    train_MSEs[i] = roc_auc_score(train_df['recommended'], train_preds)\n",
    "    val_MSEs[i] = roc_auc_score(val_df['recommended'], val_preds)\n",
    "    print(\"Training AUC: {}\".format(train_MSEs[i]))\n",
    "    print(\"Validation AUC: {}\".format(val_MSEs[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different values of k don't seem to make too much difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = './results/'\n",
    "\n",
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_cf = pd.DataFrame({'k': k_vals,\n",
    "                             'trainMSE': train_MSEs,\n",
    "                             'valMSE': val_MSEs})\n",
    "item_item_cf.to_csv(RESULTS_DIR+\"itemToItemCF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Running With All Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_avg = train_df.groupby(train_df['book_id'], as_index=False)['rating'].mean()\n",
    "train_item_avg.columns = ['book_id', 'book_average']\n",
    "train_item_avg = train_item_avg.set_index('book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with k = 1\n",
      "---------------\n",
      "Training AUC: 0.6742108369200269\n",
      "Validation AUC: 0.6050032017531815\n",
      "\n",
      "kNN with k = 2\n",
      "---------------\n",
      "Training AUC: 0.6409586002368054\n",
      "Validation AUC: 0.5868506978132447\n",
      "\n",
      "kNN with k = 5\n",
      "---------------\n",
      "Training AUC: 0.6416863174652611\n",
      "Validation AUC: 0.5798940542914955\n",
      "\n",
      "kNN with k = 10\n",
      "---------------\n",
      "Training AUC: 0.6221939209392602\n",
      "Validation AUC: 0.5644518140016275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "k_vals = [1, 2, 5, 10]\n",
    "train_MSEs = [None for _ in range(4)]\n",
    "val_MSEs = [None for _ in range(4)]\n",
    "\n",
    "for i in range(len(k_vals)):\n",
    "    k = k_vals[i]\n",
    "    print(\"kNN with k = {}\".format(k))\n",
    "    print(\"---------------\")\n",
    "    train_preds, val_preds = get_item_knn_train_validation_preds(\n",
    "        train_df, val_df, item_train_matrix, k, item_matrix.index, train_item_avg)\n",
    "    train_MSEs[i] = roc_auc_score(train_df['recommended'], train_preds)\n",
    "    val_MSEs[i] = roc_auc_score(val_df['recommended'], val_preds)\n",
    "    print(\"Training AUC: {}\".format(train_MSEs[i]))\n",
    "    print(\"Validation AUC: {}\".format(val_MSEs[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_cf = pd.DataFrame({'k': k_vals,\n",
    "                             'trainMSE': train_MSEs,\n",
    "                             'valMSE': val_MSEs})\n",
    "item_item_cf.to_csv(RESULTS_DIR+\"itemToItemCF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Item-Item Similarity based on books read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_matrix = train_df.pivot(index='book_id', columns='user_id', values='read').fillna(0)\n",
    "item_train_matrix = sp.csr_matrix(item_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_df = train_df[['book_id', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommend_preds_from_knn(knn_model, train_matrix, items, recommendation_df):\n",
    "    \"\"\"Gets the kNN predictions for the items in `items`.\n",
    "    \n",
    "    This assumes that every item in items was fit on the\n",
    "    knn_model. This is just a precomputation step to get\n",
    "    the predictions for items in the training set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    knn_model: NearestNeighbors\n",
    "        A NearestNeighbors model that has been fit.\n",
    "    train_matrix: sp.csr_matrix\n",
    "        The sparse matrix representing the training data.\n",
    "    items: np.array\n",
    "        An array of item indices for items in `knn_model`.\n",
    "    recommendation_df: pd.DataFrame\n",
    "        A pandas dataframe containing the book_id and a\n",
    "        column indicating whether the user recommended\n",
    "        the book or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing the predicted rating for each item\n",
    "        in `items`.\n",
    "    \n",
    "    \"\"\"\n",
    "    item_neighbors = np.asarray(knn_model.kneighbors(train_matrix, return_distance=False))\n",
    "    knn_avgs = np.zeros(len(item_neighbors))   # this is more efficient than appending multiple times (no resizing)\n",
    "    for i in range(len(item_neighbors)):\n",
    "        knn_avgs[i] = round(recommendation_df[recommendation_df['book_id'].isin(items[item_neighbors[i]])]['recommended'].mean())\n",
    "    return pd.concat([pd.DataFrame(items, columns=['book_id']),\n",
    "                      pd.DataFrame(knn_avgs, columns=['book_recommend'])],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_recommend(X, item_preds, default_val, merge_col):\n",
    "    \"\"\"Predicts the item ratings for the items in `X`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        The DataFrame of features.\n",
    "    item_preds: pd.DataFrame\n",
    "        The DataFrame of predicted ratings for the items.\n",
    "    default_val: float\n",
    "        A default rating used for unseen items.\n",
    "    merge_col: str\n",
    "        The column to merge on.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing the predicted item ratings for\n",
    "        the records in `X`.\n",
    "    \n",
    "    \"\"\"\n",
    "    id_col = \"{}_id\".format(merge_col)\n",
    "    recommend_col = \"{}_recommend\".format(merge_col)\n",
    "    df_item = pd.merge(X, item_preds, how='left', on=[id_col])\n",
    "    df_item[recommend_col] = df_item[recommend_col].fillna(default_val)\n",
    "    df_item.index = X.index\n",
    "    return df_item[recommend_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommend_knn_train_validation_preds(train_df, val_df, train_matrix, k, items, recommendation_df):\n",
    "    \"\"\"Gets predictions on `train_df` and `val_df` from a kNN model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df: pd.DataFrame\n",
    "        A DataFrame of the training data.\n",
    "    val_df: pd.DataFrame\n",
    "        A DataFrame of the validation data.\n",
    "    train_matrix: sp.csr_matrix\n",
    "        The sparse matrix used to train the kNN model.\n",
    "    k: int\n",
    "        The number of neighbours in the kNN model.\n",
    "    items: np.array\n",
    "        An array of strings representing the ids of the\n",
    "        items used in training.\n",
    "    recommendation_df: pd.DataFrame\n",
    "        A pandas dataframe containing the book_id and a\n",
    "        column indicating whether the user recommended\n",
    "        the book or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array, np.array\n",
    "        Arrays of predictions on the training and validation sets, respectively.\n",
    "    \n",
    "    \"\"\"\n",
    "    knn_model = build_knn_model(train_matrix, k)\n",
    "    knn_preds = get_recommend_preds_from_knn(knn_model, train_matrix, items, recommendation_df)\n",
    "    \n",
    "    # prediction for a new book\n",
    "    new_book_vec = np.zeros(train_matrix.shape[1])\n",
    "    new_book_neighbours = knn_model.kneighbors(new_book_vec.reshape(1, -1), return_distance=False)\n",
    "    new_book_pred = round(recommendation_df[recommendation_df['book_id'].isin(items[new_book_neighbours[0]])]['recommended'].mean())\n",
    "    \n",
    "    train_pred = predict_recommend(train_df, knn_preds, new_book_pred, \"book\")\n",
    "    val_pred = predict_recommend(val_df, knn_preds, new_book_pred, \"book\")\n",
    "    return train_pred, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with k = 1\n",
      "---------------\n",
      "Training AUC: 0.6716172244378682\n",
      "Validation AUC: 0.6112567493776453\n",
      "\n",
      "kNN with k = 2\n",
      "---------------\n",
      "Training AUC: 0.6675420355936391\n",
      "Validation AUC: 0.6102760423159885\n",
      "\n",
      "kNN with k = 5\n",
      "---------------\n",
      "Training AUC: 0.6678445290355558\n",
      "Validation AUC: 0.6059702134196963\n",
      "\n",
      "kNN with k = 10\n",
      "---------------\n",
      "Training AUC: 0.6586977441126709\n",
      "Validation AUC: 0.6001336897432307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_vals = [1, 2, 5, 10]\n",
    "train_MSEs = [None for _ in range(4)]\n",
    "val_MSEs = [None for _ in range(4)]\n",
    "\n",
    "for i in range(len(k_vals)):\n",
    "    k = k_vals[i]\n",
    "    print(\"kNN with k = {}\".format(k))\n",
    "    print(\"---------------\")\n",
    "    train_preds, val_preds = get_recommend_knn_train_validation_preds(\n",
    "        train_df, val_df, item_train_matrix, k, item_matrix.index, recommended_df)\n",
    "    train_MSEs[i] = roc_auc_score(train_df['recommended'], train_preds)\n",
    "    val_MSEs[i] = roc_auc_score(val_df['recommended'], val_preds)\n",
    "    print(\"Training AUC: {}\".format(train_MSEs[i]))\n",
    "    print(\"Validation AUC: {}\".format(val_MSEs[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_cf = pd.DataFrame({'k': k_vals,\n",
    "                             'trainMSE': train_MSEs,\n",
    "                             'valMSE': val_MSEs})\n",
    "item_item_cf.to_csv(RESULTS_DIR+\"itemToItemCF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we would like to run user-user collaborative filtering. The user base is just too large and it seems that chainRec is a superior model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc2515-env-3.8",
   "language": "python",
   "name": "csc2515-env-3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
