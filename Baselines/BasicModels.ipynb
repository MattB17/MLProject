{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.metrics import auc, roc_auc_score, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from files:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_data_path(dataset_name):\n",
    "    \"\"\"Constructs the path to `dataset_name`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name: str\n",
    "        The name of the dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A path to the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    return os.path.join('../output_data', '{}.csv'.format(dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_data_1 = pd.read_csv(construct_data_path('text_processed_training'))\n",
    "validation_data_1 = pd.read_csv(construct_data_path('text_processed_validation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_1.copy()\n",
    "validation_data = validation_data_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['text_reviews_count', 'is_ebook', 'average_rating', 'num_pages',\n",
    "                   'ratings_count', 'is_translated', 'is_in_series', 'series_length', \n",
    "                   'is_paperback', 'is_hardcover', 'is_audio', 'from_penguin', \n",
    "                   'from_harpercollins', 'from_university_press', 'from_vintage',\n",
    "                   'from_createspace', 'publication_year', 'author_a', 'author_b', 'author_c',\n",
    "                   'author_d', 'author_e', 'author_f', 'author_other', 'book_shelved_count',\n",
    "                   'shelved_count', 'read_count', 'rated_count', 'recommended_count', 'title_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['recommended']\n",
    "\n",
    "X_validation = validation_data[feature_columns]\n",
    "y_validation = validation_data['recommended']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_logistic_regression(X_test, X_train, y_train):\n",
    "    \"\"\"classify X_test entries with a logistic regression classifier \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DataFrame: X_test\n",
    "        A DataFrame corresponding to the test data\n",
    "        \n",
    "    DataFrame: X_train\n",
    "        A DataFrame corresponding to the train data\n",
    "        \n",
    "    list: y_train\n",
    "        A list of categories corresponding to the Xs in the X_train\n",
    "        \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list: \n",
    "        A list of predicted categories corresponding the X_test\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    regr = LogisticRegression(max_iter = 10000)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svm(X_test, X_train, y_train):\n",
    "    \"\"\"classify X_test entries with a logistic a linear support vector classifier \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DataFrame: X_test\n",
    "        A DataFrame corresponding to the test data\n",
    "        \n",
    "    DataFrame: X_train\n",
    "        A DataFrame corresponding to the train data\n",
    "        \n",
    "    list: y_train\n",
    "        A list of categories corresponding to the Xs in the X_train\n",
    "        \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list: \n",
    "        A list of predicted categories corresponding the X_test\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(), \n",
    "                        LinearSVC(random_state=0, max_iter=10000))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_forest(X_test, X_train, y_train):\n",
    "    \"\"\"classify X_test entries with a Random Forest classifier \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DataFrame: X_test\n",
    "        A DataFrame corresponding to the test data\n",
    "        \n",
    "    DataFrame: X_train\n",
    "        A DataFrame corresponding to the train data\n",
    "        \n",
    "    list: y_train\n",
    "        A list of categories corresponding to the Xs in the X_train\n",
    "        \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list: \n",
    "        A list of predicted categories corresponding the X_test\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    clf = RandomForestClassifier(n_jobs=4, n_estimators=1000, max_depth=15, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test, X_train, y_train):\n",
    "    y_pred_test = model(X_test, X_train, y_train)\n",
    "    y_pred_train = model(X_train, X_train, y_train)\n",
    "    \n",
    "    print(\"validation:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(roc_auc_score(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"train:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(roc_auc_score(y_train, y_pred_train))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.23      0.35     17586\n",
      "           1       0.54      0.92      0.68     17044\n",
      "\n",
      "    accuracy                           0.57     34630\n",
      "   macro avg       0.64      0.58      0.52     34630\n",
      "weighted avg       0.65      0.57      0.51     34630\n",
      "\n",
      "0.576169627447619\n",
      "train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.46      0.59    111170\n",
      "           1       0.69      0.92      0.79    146475\n",
      "\n",
      "    accuracy                           0.72    257645\n",
      "   macro avg       0.75      0.69      0.69    257645\n",
      "weighted avg       0.74      0.72      0.70    257645\n",
      "\n",
      "0.6908926830991556\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_logistic_regression, X_validation, y_validation, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67     17586\n",
      "           1       0.66      0.61      0.64     17044\n",
      "\n",
      "    accuracy                           0.66     34630\n",
      "   macro avg       0.66      0.66      0.66     34630\n",
      "weighted avg       0.66      0.66      0.66     34630\n",
      "\n",
      "0.6569771662632047\n",
      "train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78    111170\n",
      "           1       0.84      0.81      0.83    146475\n",
      "\n",
      "    accuracy                           0.80    257645\n",
      "   macro avg       0.80      0.80      0.80    257645\n",
      "weighted avg       0.81      0.80      0.80    257645\n",
      "\n",
      "0.8028121594786715\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_random_forest, X_validation, y_validation, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.42      0.52      5087\n",
      "           1       0.57      0.79      0.66      4913\n",
      "\n",
      "    accuracy                           0.60     10000\n",
      "   macro avg       0.62      0.61      0.59     10000\n",
      "weighted avg       0.62      0.60      0.59     10000\n",
      "\n",
      "0.6062111364836817\n",
      "train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64     21513\n",
      "           1       0.72      0.82      0.76     28487\n",
      "\n",
      "    accuracy                           0.71     50000\n",
      "   macro avg       0.71      0.70      0.70     50000\n",
      "weighted avg       0.71      0.71      0.71     50000\n",
      "\n",
      "0.6978785369149139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "test_model(predict_svm, X_validation[:10000], y_validation[:10000], X_train[:50000], y_train[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
